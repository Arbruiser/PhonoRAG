{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import llama_index.core\n",
    "from llama_index.core import VectorStoreIndex, StorageContext, load_index_from_storage\n",
    "from llama_index.core import Settings\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.postprocessor import SimilarityPostprocessor\n",
    "from llama_parse import LlamaParse\n",
    "import nest_asyncio; nest_asyncio.apply()\n",
    "\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data and index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['raw_texts/2-settext.pdf', 'raw_texts/3-settext.txt', 'raw_texts/3-slides.pdf', 'raw_texts/4-settext.pdf', 'raw_texts/4-slides.pdf', 'raw_texts/5-settext.pdf', 'raw_texts/9-settext.pdf']\n",
      "['JSON_quizzes_only_closed_questions/itembank-2.json', 'JSON_quizzes_only_closed_questions/itembank-3-4.json', 'JSON_quizzes_only_closed_questions/itembank-5-6.json', 'JSON_quizzes_only_closed_questions/itembank-9a.json', 'JSON_quizzes_only_closed_questions/itembank-9b.json']\n"
     ]
    }
   ],
   "source": [
    "BP_threshold = 30\n",
    "top_k = 24 # set how many chunks are given as context to GPT\n",
    "\n",
    "PERSIST_DIR = f\"./storage_SDR_semantic_chunking_various_thresholds/storage_SDR_sem_{BP_threshold}_text-embedding-ada-002\"\n",
    "\n",
    "storage_context = StorageContext.from_defaults(persist_dir=PERSIST_DIR)\n",
    "index = load_index_from_storage(storage_context)\n",
    "\n",
    "LIST_OF_DOCS = [\"raw_texts/\"+f for f in os.listdir(\"Raw_texts\")]\n",
    "print(LIST_OF_DOCS)\n",
    "\n",
    "# Open quizzes\n",
    "LIST_OF_QUIZZES = [\"JSON_quizzes_only_closed_questions/\"+f for f in os.listdir(\"./JSON_quizzes_only_closed_questions\") if f.endswith('.json')]\n",
    "print(LIST_OF_QUIZZES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"gpt-4o-mini\"\n",
    "\n",
    "Settings.llm = OpenAI(temperature=0.0, model=model)\n",
    "\n",
    "def pingGPT(text_input):\n",
    "   response = query_engine.query(text_input)\n",
    "   return response.response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The retriever with default prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure retriever\n",
    "retriever = VectorIndexRetriever(\n",
    "    index=index,\n",
    "    similarity_top_k=top_k,\n",
    ")\n",
    "\n",
    "# configure response synthesizer\n",
    "\n",
    "# assemble query engine\n",
    "query_engine = RetrieverQueryEngine(\n",
    "    retriever=retriever,\n",
    "    node_postprocessors=[SimilarityPostprocessor(similarity_cutoff=0.7)],\n",
    ")\n",
    "\n",
    "from llama_index.core import PromptTemplate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------processing itembank-2----------\n",
      "----------processing itembank-3-4----------\n",
      "----------processing itembank-5-6----------\n",
      "----------processing itembank-9a----------\n",
      "----------processing itembank-9b----------\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "total_nquestions = 0\n",
    "total_ncorrects = 0\n",
    "itembank_reports = []\n",
    "\n",
    "itembank_reports.append(f\"breakpoint percentile: {BP_threshold}\")\n",
    "itembank_reports.append(f\"top_k: {top_k}\")\n",
    "\n",
    "# Iterate over each question and get GPT's response\n",
    "for doc in LIST_OF_QUIZZES:\n",
    "    with open(doc, 'r', encoding='UTF-8') as file:\n",
    "        questions_JSON = json.load(file)\n",
    "    \n",
    "    itembank_number = re.search(r\"\\d[a|b]?(?:\\-\\d)?\", doc).group()\n",
    "    this_ncorrects = 0 # for correct answers in each separate itembank\n",
    "    this_nquestions = 0\n",
    "\n",
    "    print(f\"----------processing itembank-{itembank_number}----------\")\n",
    "\n",
    "    for question in questions_JSON:\n",
    "        full_prompt = question['question'] + '\\n' + '\\n'.join(question['answers'])\n",
    "        given_answer = pingGPT(full_prompt)  # Get the response from GPT\n",
    "        question[\"GPT's response\"] = given_answer  # Append the response to the question\n",
    "        question[\"correct\"] = given_answer==question[\"correct answer(s)\"]\n",
    "\n",
    "        this_nquestions+=1\n",
    "        total_nquestions+=1\n",
    "        if given_answer==question[\"correct answer(s)\"]:\n",
    "            total_ncorrects+=1\n",
    "            this_ncorrects+=1\n",
    "        \n",
    "    itembank_reports.append(f\"itembank-{itembank_number}:\\t\\tCorrect answers {this_ncorrects} / total questions {this_nquestions} * 100 = {round(this_ncorrects/this_nquestions*100, 2)}%\")\n",
    "\n",
    "\n",
    "    # Save the updated JSON data to a new file\n",
    "    with open(f'./results/improved_RAG_responses/semantic_chunking/RAG_{model}_semantic_{BP_threshold}_responses-{itembank_number}.json', 'w') as outfile:\n",
    "        json.dump(questions_JSON, outfile, indent=2)\n",
    "\n",
    "itembank_reports.append(f\"\\nOverall correct answers {total_ncorrects} / total questions {total_nquestions} * 100 = {round(total_ncorrects/total_nquestions*100, 2)}%\\n\")\n",
    "itembank_reports.append(\"------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "# save the prompt and number of correct questions\n",
    "with open(f\"./results/default_RAG_{model}_semantic_chunking_results.txt\", 'a', encoding='UTF-8') as report_file:\n",
    "    report_file.write('\\n'.join(itembank_reports))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observe with Phoenix (not necessary to run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OTEL_EXPORTER_OTLP_HEADERS\"] = f\"api_key={os.getenv('PHOENIX_API_KEY')}\"\n",
    "llama_index.core.set_global_handler(\"arize_phoenix\", endpoint=\"https://llamatrace.com/v1/traces\")\n",
    "\n",
    "with open('./JSON_questions_only_closed_questions/itembank-3-4.json', 'r', encoding='UTF-8') as file:\n",
    "    questions_JSON = json.load(file)\n",
    "\n",
    "for question in questions_JSON[18:19]:\n",
    "    full_prompt = question['question'] + '\\n' + '\\n'.join(question['answers'])\n",
    "    given_answer = pingGPT(full_prompt)  # Get the response from GPT\n",
    "print(given_answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
