{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import llama_index.core\n",
    "from llama_index.core import VectorStoreIndex, StorageContext, load_index_from_storage, SimpleDirectoryReader\n",
    "from llama_index.core import Settings\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.postprocessor import SimilarityPostprocessor\n",
    "from llama_parse import LlamaParse\n",
    "from llama_index.core.node_parser import SentenceSplitter, SemanticSplitterNodeParser\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "import nest_asyncio; nest_asyncio.apply()\n",
    "\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"gpt-4o\"\n",
    "embedding_model = \"text-embedding-3-large\"\n",
    "similarity_cutoff = 0.6\n",
    "\n",
    "# set GPT's temperature to 0\n",
    "Settings.llm = OpenAI(temperature=0.0, model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"gpt-4o-mini\"\n",
    "embedding_model = \"text-embedding-ada-002\"\n",
    "similarity_cutoff = 0\n",
    "\n",
    "# set GPT's temperature to 0\n",
    "Settings.llm = OpenAI(temperature=0.0, model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['raw_texts/2-settext.pdf', 'raw_texts/3-settext.txt', 'raw_texts/4-settext.pdf', 'raw_texts/5-settext.pdf', 'raw_texts/9-settext.pdf']\n"
     ]
    }
   ],
   "source": [
    "BP_threshold = 70\n",
    "top_k = 10 # set how many chunks are given as context to GPT\n",
    "\n",
    "PERSIST_DIR = f\"./storage_LlamaParse_semantic_chunking_final/storage_LlamaParse_sem_{BP_threshold}_{embedding_model}\"\n",
    "\n",
    "LIST_OF_DOCS = [\"raw_texts/\"+f for f in os.listdir(\"Raw_texts\")]\n",
    "print(LIST_OF_DOCS)\n",
    "\n",
    "if not os.path.exists(PERSIST_DIR):\n",
    "    embed_model_OpenAI = OpenAIEmbedding(model=embedding_model)\n",
    "    documents = LlamaParse(result_type=\"text\").load_data(LIST_OF_DOCS)\n",
    "    splitter = SemanticSplitterNodeParser(buffer_size=1, breakpoint_percentile_threshold=BP_threshold, embed_model=embed_model_OpenAI, include_metadata=True)\n",
    "    nodes = splitter.get_nodes_from_documents(documents)\n",
    "    # load the documents and create the index\n",
    "    index = VectorStoreIndex(nodes)\n",
    "    # store it for later\n",
    "    index.storage_context.persist(persist_dir=PERSIST_DIR)\n",
    "else:\n",
    "    # load the existing index\n",
    "    storage_context = StorageContext.from_defaults(persist_dir=PERSIST_DIR)\n",
    "    index = load_index_from_storage(storage_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open quizzes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['JSON_quizzes/GPT-made_quizzes/itembank-2.json', 'JSON_quizzes/GPT-made_quizzes/itembank-3.json', 'JSON_quizzes/GPT-made_quizzes/itembank-4.json', 'JSON_quizzes/GPT-made_quizzes/itembank-5.json', 'JSON_quizzes/GPT-made_quizzes/itembank-9.json', 'JSON_quizzes/my_own_quizzes/itembank-2.json', 'JSON_quizzes/my_own_quizzes/itembank-3.json', 'JSON_quizzes/my_own_quizzes/itembank-4.json', 'JSON_quizzes/my_own_quizzes/itembank-5.json', 'JSON_quizzes/my_own_quizzes/itembank-9.json']\n",
      "number of quizzes: 10\n"
     ]
    }
   ],
   "source": [
    "GPT_made_quizzes = [\"JSON_quizzes/GPT-made_quizzes/\"+f for f in os.listdir(\"./JSON_quizzes/GPT-made_quizzes\") if f.endswith('.json')]\n",
    "my_own_quizzes = [\"JSON_quizzes/my_own_quizzes/\"+f for f in os.listdir(\"./JSON_quizzes/my_own_quizzes\") if f.endswith('.json')]\n",
    "LIST_OF_QUIZZES = GPT_made_quizzes + my_own_quizzes\n",
    "\n",
    "print(LIST_OF_QUIZZES)\n",
    "print(\"number of quizzes:\", len(LIST_OF_QUIZZES))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The retriever and prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure retriever\n",
    "retriever = VectorIndexRetriever(\n",
    "    index=index,\n",
    "    similarity_top_k=top_k,\n",
    ")\n",
    "\n",
    "# configure response synthesizer\n",
    "\n",
    "# assemble query engine\n",
    "query_engine = RetrieverQueryEngine(\n",
    "    retriever=retriever,\n",
    "    node_postprocessors=[SimilarityPostprocessor(similarity_cutoff=similarity_cutoff)],\n",
    ")\n",
    "\n",
    "from llama_index.core import PromptTemplate\n",
    "\n",
    "new_prompt = (\n",
    "    \"Context information is below.\\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"{context_str}\\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"Given the context information and not prior knowledge, \"\n",
    "    \"answer the query. The context is incredibly important, read and analyze it extremely carefully! Make sure that the answer is 100% correct because my life depends on it. \"\n",
    "    \"Only answer with the letter and text of the answer which you think is correct.\\n\"\n",
    "    \"Question: {query_str}\\n\"\n",
    "    \"Answer: \"\n",
    ")\n",
    "new_tmpl = PromptTemplate(new_prompt)\n",
    "\n",
    "query_engine.update_prompts(\n",
    "    {\"response_synthesizer:text_qa_template\": new_tmpl}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pass over the quizzes number 1\n",
      "\n",
      "Pass over the quizzes number 2\n",
      "\n",
      "Pass over the quizzes number 3\n",
      "\n",
      "Pass over the quizzes number 4\n",
      "\n",
      "Pass over the quizzes number 5\n"
     ]
    }
   ],
   "source": [
    "for pass_n in range(5):\n",
    "    print(f\"\\nPass over the quizzes number {pass_n+1}\")    \n",
    "    \n",
    "    #save total number of questions and correct answers separately for my own quizzes and GPT-made\n",
    "    total_nquestions_own = 0\n",
    "    total_ncorrects_own = 0\n",
    "    total_nquestions_GPT = 0\n",
    "    total_ncorrects_GPT = 0\n",
    "\n",
    "    itembank_reports = [] # to write the itembank number and number of correct answers.\n",
    "    itembank_reports.append(f\"breakpoint percentile: {BP_threshold}\")\n",
    "    itembank_reports.append(f\"top_k: {top_k}\")\n",
    "    itembank_reports.append(f\"embedding model: {embedding_model}\")\n",
    "    itembank_reports.append(f\"similarity cutoff: {similarity_cutoff}\")\n",
    "    itembank_reports.append(f\"\\nPrompt:\\n {new_prompt}\\n\")\n",
    "\n",
    "\n",
    "    # Iterate over each question and get GPT's response\n",
    "    for doc in LIST_OF_QUIZZES:\n",
    "        with open(doc, 'r', encoding='UTF-8') as file:\n",
    "            itembank_JSON = json.load(file)\n",
    "        \n",
    "        itembank_number = re.search(r\"\\d[a|b]?(?:\\-\\d)?\", doc).group()\n",
    "        quiz_type = \"own_questions\" if re.search(r\"my_own_quizzes\", doc) else \"GPT-made_questions\" # returns None for GPT-made questions\n",
    "        this_ncorrects = 0 # for correct answers in each separate itembank\n",
    "        this_nquestions = 0\n",
    "\n",
    "        #print(f\"----------processing itembank-{itembank_number}-{quiz_type}----------\")\n",
    "\n",
    "        for question in itembank_JSON:\n",
    "            full_prompt = question['question'] + '\\n' + '\\n'.join(question['answers'])\n",
    "            given_answer = query_engine.query(full_prompt).response # Get the response from GPT\n",
    "            question[\"GPT's response\"] = given_answer  # Append the response to the question\n",
    "            question[\"correct\"] = given_answer==question[\"correct answer(s)\"]\n",
    "\n",
    "            if quiz_type == \"own_questions\":\n",
    "                if given_answer==question[\"correct answer(s)\"]: \n",
    "                    total_ncorrects_own+=1\n",
    "                    this_ncorrects+=1\n",
    "                total_nquestions_own+=1\n",
    "                this_nquestions+=1\n",
    "            else:\n",
    "                if given_answer==question[\"correct answer(s)\"]: \n",
    "                    total_ncorrects_GPT+=1\n",
    "                    this_ncorrects+=1\n",
    "                total_nquestions_GPT+=1\n",
    "                this_nquestions+=1\n",
    "            \n",
    "        itembank_reports.append(f\"itembank-{itembank_number}_{quiz_type}:\\t\\tCorrect answers {this_ncorrects} / total questions {this_nquestions} * 100 = {round(this_ncorrects/this_nquestions*100, 2)}%\")\n",
    "\n",
    "        # Save the updated JSON data to a new file\n",
    "        with open(f'./results/improved_RAG_responses/semantic_chunking/RAG_{model}_responses-semantic_{BP_threshold}-{itembank_number}_{quiz_type}.json', 'w') as outfile:\n",
    "            json.dump(itembank_JSON, outfile, indent=2)\n",
    "\n",
    "    itembank_reports.append(f\"\\nOverall correct answers for GPT-made {total_ncorrects_GPT} / total questions {total_nquestions_GPT} * 100 = {round(total_ncorrects_GPT/total_nquestions_GPT*100, 2)}%\")\n",
    "    itembank_reports.append(f\"Overall correct answers for own {total_ncorrects_own} / total questions {total_nquestions_own} * 100 = {round(total_ncorrects_own/total_nquestions_own*100, 2)}%\\n\")\n",
    "    itembank_reports.append(\"\\n------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "    # save the prompt and number of correct questions\n",
    "    with open(f\"./results/improved_rag_{model}_results.txt\", 'a', encoding='UTF-8') as report_file:\n",
    "        report_file.write('\\n'.join(itembank_reports))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observe with Phoenix (not necessary to run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OTEL_EXPORTER_OTLP_HEADERS\"] = f\"api_key={os.getenv('PHOENIX_API_KEY')}\"\n",
    "llama_index.core.set_global_handler(\"arize_phoenix\", endpoint=\"https://llamatrace.com/v1/traces\")\n",
    "\n",
    "with open('./JSON_quizzes/my_own_quizzes/itembank-4.json', 'r', encoding='UTF-8') as file:\n",
    "    questions_JSON = json.load(file)\n",
    "\n",
    "for question in questions_JSON[18:19]:\n",
    "    full_prompt = question['question'] + '\\n' + '\\n'.join(question['answers'])\n",
    "    given_answer = pingGPT(full_prompt)  # Get the response from GPT\n",
    "print(given_answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
