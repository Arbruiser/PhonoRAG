{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nest_asyncio; nest_asyncio.apply()\n",
    "import re\n",
    "\n",
    "import json\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function that sends questions to GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "model=\"gpt-4o\"\n",
    "temp = 0\n",
    "system_message = r\"You're an expert in answering quiz questions about phonology.\"\n",
    "\n",
    "def pingGPT(prompt, model=model):\n",
    "   # Creating a message as required by the API\n",
    "   messages = [{\"role\":\"system\", \"content\": system_message},\n",
    "               {\"role\": \"user\", \"content\": prompt}]\n",
    "  \n",
    "   # Calling the ChatCompletion API\n",
    "   response = client.chat.completions.create(\n",
    "       model=model,\n",
    "       messages=messages,\n",
    "       temperature=temp,\n",
    "   )\n",
    "\n",
    "   # Returning the extracted response\n",
    "   return response.choices[0].message.content\n",
    "\n",
    "def assemble_prompt(question):\n",
    "   context = f\"Context information is below.\\n----------------\\n{question['correct_text_chunk']}\\nGiven the context information and not prior knowledge, answer the question. Only answer with the letter and text of the answer which you think is correct:\\n\"\n",
    "   return(context + question['question']+'\\n' + '\\n'.join(question['answers']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['oracle/JSON_oracles/oracle-itembank-2.json', 'oracle/JSON_oracles/oracle-itembank-3.json', 'oracle/JSON_oracles/oracle-itembank-4.json', 'oracle/JSON_oracles/oracle-itembank-5.json', 'oracle/JSON_oracles/oracle-itembank-9.json']\n",
      "number of quizzes: 5\n"
     ]
    }
   ],
   "source": [
    "LIST_OF_QUIZZES = [\"oracle/JSON_oracles/\"+f for f in os.listdir(\"./oracle/JSON_oracles/\") if f.endswith('.json')]\n",
    "\n",
    "print(LIST_OF_QUIZZES)\n",
    "print(\"number of quizzes:\", len(LIST_OF_QUIZZES))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open an itembank, send the questions to raw GPT-4o, obtain and save the responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pass over all the itembanks number 1\n",
      "----------processing itembank-2----------\n",
      "----------processing itembank-3----------\n",
      "----------processing itembank-4----------\n",
      "----------processing itembank-5----------\n",
      "----------processing itembank-9----------\n",
      "\n",
      "Pass over all the itembanks number 2\n",
      "----------processing itembank-2----------\n",
      "----------processing itembank-3----------\n",
      "----------processing itembank-4----------\n",
      "----------processing itembank-5----------\n",
      "----------processing itembank-9----------\n",
      "\n",
      "Pass over all the itembanks number 3\n",
      "----------processing itembank-2----------\n",
      "----------processing itembank-3----------\n",
      "----------processing itembank-4----------\n",
      "----------processing itembank-5----------\n",
      "----------processing itembank-9----------\n"
     ]
    }
   ],
   "source": [
    "# save total number of questions and correct answers separately for my own quizzes and GPT-made\n",
    "total_nquestions = 0\n",
    "total_ncorrects = 0\n",
    "\n",
    "itembank_reports = [] # to write the itembank number and number of correct answers.\n",
    "itembank_reports.append(f\"Model: {model}\")\n",
    "itembank_reports.append(f\"Temperature: {temp}\")\n",
    "itembank_reports.append(f\"System message: {system_message}\\n\")\n",
    "\n",
    "for run_n in range(3): # make three passes over all the quizzes\n",
    "    print(f\"\\nPass over all the itembanks number {run_n+1}\")\n",
    "    for doc in LIST_OF_QUIZZES:\n",
    "        with open(doc, 'r', encoding='UTF-8') as file:\n",
    "            quiz_JSON = json.load(file)\n",
    "        \n",
    "        itembank_number = re.search(r\"\\d[a|b]?(?:\\-\\d)?\", doc).group()\n",
    "\n",
    "        print(f\"----------processing itembank-{itembank_number}----------\")\n",
    "        \n",
    "        this_ncorrects = 0 # for correct answers in each separate itembank\n",
    "        this_nquestions = 0\n",
    "\n",
    "        # main loop that sends requests and saves answers\n",
    "        for question in quiz_JSON:\n",
    "            full_prompt = assemble_prompt(question)\n",
    "            given_answer = pingGPT(full_prompt)  # Get the response from GPT\n",
    "            question[\"GPT's response\"] = given_answer  # Append the response to the question\n",
    "            question[\"correct\"] = given_answer==question[\"correct answer(s)\"] # stores whether the answer is correct\n",
    "            \n",
    "            # count how many total responses are correct\n",
    "            if given_answer==question[\"correct answer(s)\"]: \n",
    "                total_ncorrects+=1\n",
    "                this_ncorrects+=1\n",
    "            this_nquestions+=1\n",
    "            total_nquestions+=1\n",
    "\n",
    "        \n",
    "        itembank_reports.append(f\"itembank-{itembank_number}:\\t\\tCorrect answers {this_ncorrects} / total questions {this_nquestions} * 100 = {round(this_ncorrects/this_nquestions*100, 2)}%\")\n",
    "\n",
    "        # Save the updated JSON data to a new file\n",
    "        with open(f'./results/oracle_responses/oracle-{itembank_number}_responses.json', 'w') as outfile:\n",
    "            json.dump(quiz_JSON, outfile, indent=2)\n",
    "    itembank_reports.append(\" \")\n",
    "\n",
    "itembank_reports.append(f\"\\nOverall correct answers {total_ncorrects} / total questions {total_nquestions} * 100 = {round(total_ncorrects/total_nquestions*100, 2)}%\")\n",
    "itembank_reports.append(\"\\n------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "# save the prompt and number of correct questions\n",
    "with open(f\"./results/oracle_{model}_results.txt\", 'a', encoding='UTF-8') as report_file:\n",
    "    report_file.write('\\n'.join(itembank_reports))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "841\n"
     ]
    }
   ],
   "source": [
    "print(total_ncorrects)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
